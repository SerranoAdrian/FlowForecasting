{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "\n",
    "from gnn_model import StationFlowGCN, StationFlowGAT\n",
    "from train_gnn import(\n",
    "    train_gnn_model,\n",
    "    eval_gnn_model,\n",
    "    regul_edge_node_flow\n",
    ")\n",
    "from utils.station_network import StationNetworkSimul\n",
    "from utils.data import get_degraded_network_loader, create_degraded_networks\n",
    "from utils.plot import(\n",
    "    boxplot_node_metric,\n",
    "    boxplot_node_metric_per_line,\n",
    "    plot_true_predicted,\n",
    "    plot_predicted_ape,\n",
    ")\n",
    "from utils.metrics import (\n",
    "    get_metric_per_node_per_network,\n",
    "    MAPE_loss,\n",
    "    WAPE_loss,\n",
    "    WMAPE_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv('plan du métro.csv')\n",
    "df_stations = df_stations[~df_stations['vers Ligne'].isin(['\\xa01', '\\xa07', '\\xa02', '\\xa08', '\\xa06'])]\n",
    "\n",
    "df_pos = pd.read_csv(\"position gps des stations de métro.csv\")\n",
    "\n",
    "#Removing Malsesherbes RER Station\n",
    "df_pos = df_pos.drop([151])\n",
    "\n",
    "df_flow = pd.read_csv('passagers.csv')\n",
    "df_flow['nombre'] = df_flow['nombre'].astype(float)\n",
    "test_network = StationNetworkSimul(df_stations=df_stations, df_pos=df_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNCOMMENT TO GENERATE DATA\n",
    "\n",
    "# test_network.set_edges_weights()\n",
    "# test_network.set_nodes_traffic(test_network.network_graph, df_flow=df_flow)\n",
    "\n",
    "# data_dir = \"graph_dataset/\"\n",
    "# for i in range(1,11):\n",
    "#     create_degraded_networks(test_network, df_flow, num_delete=i, num_degraded=100, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"graph_dataset/\"\n",
    "\n",
    "train_degraded_graphs = {i : [] for i in range(1,11)}\n",
    "dev_degraded_graphs = {i : [] for i in range(1,11)}\n",
    "test_degraded_graphs = {i : [] for i in range(1,11)}\n",
    "\n",
    "train_test_ratio = 0.9\n",
    "dev_train_ratio = 0.1\n",
    "\n",
    "for i in range(1,11):\n",
    "    folder_path = os.path.join(data_dir, f'delete_{i}')\n",
    "    all_files = [file_path for file_path in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file_path))]\n",
    "    degraded_graphs = []\n",
    "    for file_path in all_files:\n",
    "        with open(os.path.join(folder_path, file_path), 'rb') as f:\n",
    "            new_net = pickle.load(f)\n",
    "        degraded_graphs.append(new_net)\n",
    "    \n",
    "    train_split_idx = int(train_test_ratio*len(all_files))\n",
    "    dev_split_idx = int(dev_train_ratio*train_split_idx)\n",
    "\n",
    "    dev_degraded_graphs[i].extend(degraded_graphs[:dev_split_idx])\n",
    "    train_degraded_graphs[i].extend(degraded_graphs[dev_split_idx:train_split_idx])\n",
    "    test_degraded_graphs[i].extend(degraded_graphs[train_split_idx:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCNConv Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = dict(\n",
    "    epochs = 20,\n",
    "    lr = 0.01,\n",
    "    criterion = dict(\n",
    "        node=torch.nn.L1Loss(),\n",
    "        edge=torch.nn.L1Loss(),\n",
    "        # regul=regul_edge_node_flow(),\n",
    "    ),\n",
    "    metrics = dict(\n",
    "        MAE=torch.nn.L1Loss(),\n",
    "        MAPE=MAPE_loss()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using node position as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = dict(\n",
    "    node_target_name = 'traffic',\n",
    "    edge_target_name = 'traffic',\n",
    "    node_feature_names=['x', 'y'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "total_train_degraded_graphs = list(chain.from_iterable([train_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_dev_degraded_graphs = list(chain.from_iterable([dev_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_test_degraded_graphs = list(chain.from_iterable([test_degraded_graphs[i] for i in range(1,11)]))\n",
    "\n",
    "train_loader = get_degraded_network_loader(total_train_degraded_graphs, **loader_config)\n",
    "dev_loader = get_degraded_network_loader(total_dev_degraded_graphs, **loader_config)\n",
    "test_loader = get_degraded_network_loader(total_test_degraded_graphs, **loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_loader.dataset[0].x.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "nodes_gnn_model = StationFlowGCN(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_nodes=train_loader.dataset[0].x.shape[0],\n",
    ")\n",
    "\n",
    "train_gnn_model(nodes_gnn_model, train_config, train_loader, dev_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = eval_gnn_model(nodes_gnn_model, test_loader,train_config)\n",
    "print(\"\\t\".join([f\"{metric_name}: {metric_value}\" for metric_name, metric_value in test_metrics.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = random.choice(test_loader.dataset)\n",
    "test_data = test_loader.dataset[0]\n",
    "x, edge_index = test_data.x, test_data.edge_index\n",
    "output, _ = nodes_gnn_model(x, edge_index)\n",
    "\n",
    "actual_flows = test_data.y\n",
    "predicted_flows = output.detach().squeeze(1)\n",
    "\n",
    "plot_true_predicted(predicted_flows, actual_flows)\n",
    "plot_predicted_ape(predicted_flows, actual_flows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using node embedding as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialized + updated during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Unweighted edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = dict(\n",
    "    node_target_name = 'traffic',\n",
    "    edge_target_name = 'traffic',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "total_train_degraded_graphs = list(chain.from_iterable([train_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_dev_degraded_graphs = list(chain.from_iterable([dev_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_test_degraded_graphs = list(chain.from_iterable([test_degraded_graphs[i] for i in range(1,11)]))\n",
    "\n",
    "train_loader = get_degraded_network_loader(total_train_degraded_graphs, **loader_config)\n",
    "dev_loader = get_degraded_network_loader(total_dev_degraded_graphs, **loader_config)\n",
    "test_loader = get_degraded_network_loader(total_test_degraded_graphs, **loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "output_dim = 1\n",
    "\n",
    "nodes_gnn_model = StationFlowGCN(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_nodes=train_loader.dataset[0].x.shape[0],\n",
    "    embeddings='initialized'\n",
    ")\n",
    "\n",
    "train_gnn_model(nodes_gnn_model, train_config, train_loader, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae_plot = []\n",
    "# for n_del, degraded_nets in test_degraded_graphs.items():\n",
    "#     loader = get_degraded_network_loader(degraded_nets, **loader_config)\n",
    "#     metrics = eval_gnn_model(nodes_gnn_model, loader,train_config)\n",
    "#     mae_plot.append(metrics['node']['MAPE']*100)\n",
    "\n",
    "# plt.plot(range(1,11), mae_plot)\n",
    "# plt.title('MAPE w.r.t. the number of edges deleted')\n",
    "# plt.xlabel('Num. deleted')\n",
    "# plt.ylabel('MAPE (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = eval_gnn_model(nodes_gnn_model, test_loader,train_config)\n",
    "print(\"\\t\".join([f\"{metric_name}: {metric_value}\" for metric_name, metric_value in test_metrics.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_idx = np.random.randint(0, len(test_loader))\n",
    "# test_data = test_loader.dataset[random_idx]\n",
    "test_data = test_loader.dataset[18]\n",
    "x, edge_index = test_data.x, test_data.edge_index\n",
    "node_output, edge_output  = nodes_gnn_model(x, edge_index)\n",
    "\n",
    "node_actual_flows = test_data.y\n",
    "edge_actual_flows = test_data.ye\n",
    "\n",
    "node_predicted_flows= node_output.detach().squeeze(1)\n",
    "edge_predicted_flows= edge_output.detach().squeeze(1)\n",
    "\n",
    "current_edges = list(zip(edge_index[0].numpy(), edge_index[1].numpy()))\n",
    "removed_edges = list(set(test_network.network_graph.edges) - set(current_edges))\n",
    "\n",
    "removed_edges_name = [\n",
    "    f'{test_network.reverse_network_stations[edge[0]][\"title\"]} ({test_network.reverse_network_stations[edge[0]][\"group\"]}) -> {test_network.reverse_network_stations[edge[1]][\"title\"] } ({test_network.reverse_network_stations[edge[1]][\"group\"]})'\n",
    "    for edge in removed_edges\n",
    "    ]\n",
    "\n",
    "plot_true_predicted(node_predicted_flows, node_actual_flows, removed_edges_name=removed_edges_name)\n",
    "plot_true_predicted(edge_predicted_flows, edge_actual_flows, removed_edges_name=removed_edges_name)\n",
    "# plot_predicted_ape(predicted_flows, actual_flows, removed_edges_name=removed_edges_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using edges weights (based on node position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = dict(\n",
    "    node_target_name = 'traffic',\n",
    "    edge_target_name = 'traffic',\n",
    "    edge_feature_names = ['weight'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "total_train_degraded_graphs = list(chain.from_iterable([train_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_dev_degraded_graphs = list(chain.from_iterable([dev_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_test_degraded_graphs = list(chain.from_iterable([test_degraded_graphs[i] for i in range(1,11)]))\n",
    "\n",
    "\n",
    "train_loader = get_degraded_network_loader(total_train_degraded_graphs, **loader_config)\n",
    "dev_loader = get_degraded_network_loader(total_dev_degraded_graphs, **loader_config)\n",
    "test_loader = get_degraded_network_loader(total_test_degraded_graphs, **loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "output_dim = 1\n",
    "\n",
    "nodes_gnn_model = StationFlowGCN(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_nodes=train_loader.dataset[0].x.shape[0],\n",
    "    embeddings='initialized'\n",
    ")\n",
    "\n",
    "train_gnn_model(nodes_gnn_model, train_config, train_loader, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = eval_gnn_model(nodes_gnn_model, test_loader, train_config)\n",
    "print(\"\\t\".join([f\"{metric_name}: {metric_value}\" for metric_name, metric_value in test_metrics.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = MAPE_loss(reduction='none')\n",
    "df_ape_per_node_per_network = get_metric_per_node_per_network(nodes_gnn_model, test_loader, metric, test_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_node_metric(df_ape_per_node_per_network, node_idx=12, network_simul=test_network, metric_name='APE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_node_metric_per_line(df_ape_per_node_per_network, '7', test_network, 'APE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_loader.dataset[18]\n",
    "x, edge_index = test_data.x, test_data.edge_index\n",
    "node_output, edge_output  = nodes_gnn_model(x, edge_index)\n",
    "\n",
    "node_actual_flows = test_data.y\n",
    "edge_actual_flows = test_data.ye\n",
    "\n",
    "node_predicted_flows= node_output.detach().squeeze(1)\n",
    "edge_predicted_flows= edge_output.detach().squeeze(1)\n",
    "\n",
    "current_edges = list(zip(edge_index[0].numpy(), edge_index[1].numpy()))\n",
    "removed_edges = list(set(test_network.network_graph.edges) - set(current_edges))\n",
    "\n",
    "removed_edges_name = [\n",
    "    f'{test_network.reverse_network_stations[edge[0]][\"title\"]} ({test_network.reverse_network_stations[edge[0]][\"group\"]}) -> {test_network.reverse_network_stations[edge[1]][\"title\"] } ({test_network.reverse_network_stations[edge[1]][\"group\"]})'\n",
    "    for edge in removed_edges\n",
    "    ]\n",
    "\n",
    "plot_true_predicted(node_predicted_flows, node_actual_flows, removed_edges_name=removed_edges_name)\n",
    "plot_predicted_ape(node_predicted_flows, actual_flows)\n",
    "plot_true_predicted(edge_predicted_flows, edge_actual_flows, removed_edges_name=removed_edges_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Node2Vec embeddings as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = torch.tensor([i for i in sorted(test_network.network_graph.nodes)], dtype=torch.int)\n",
    "tensor_edges = torch.tensor([\n",
    "    [edge[0] for edge in sorted(test_network.network_graph.edges)],\n",
    "    [edge[1] for edge in sorted(test_network.network_graph.edges)]\n",
    "    ], dtype=torch.long)\n",
    "init_data_graph = Data(x=node_idx, edge_index=tensor_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n2v = Node2Vec(\n",
    "    init_data_graph.edge_index,\n",
    "    embedding_dim=100,\n",
    "    walks_per_node=10,\n",
    "    walk_length=20,\n",
    "    context_size=10,\n",
    "    p=1.0,\n",
    "    q=1.0,\n",
    "    num_negative_samples=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_n2v = model_n2v.loader(batch_size=128, shuffle=True)\n",
    "optimizer_n2v = optim.Adam(model_n2v.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n2v.train()\n",
    "for pos_rw, neg_rw in loader_n2v:\n",
    "    optimizer_n2v.zero_grad()\n",
    "    loss = model_n2v.loss(pos_rw, neg_rw)\n",
    "    loss.backward()\n",
    "    optimizer_n2v.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_n2v = model_n2v()\n",
    "isinstance(embeddings_n2v, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = dict(\n",
    "    node_target_name = 'traffic',\n",
    "    edge_target_name = 'traffic',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "total_train_degraded_graphs = list(chain.from_iterable([train_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_dev_degraded_graphs = list(chain.from_iterable([dev_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_test_degraded_graphs = list(chain.from_iterable([test_degraded_graphs[i] for i in range(1,11)]))\n",
    "\n",
    "\n",
    "train_loader = get_degraded_network_loader(total_train_degraded_graphs, **loader_config)\n",
    "dev_loader = get_degraded_network_loader(total_dev_degraded_graphs, **loader_config)\n",
    "test_loader = get_degraded_network_loader(total_test_degraded_graphs, **loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "output_dim = 1\n",
    "\n",
    "nodes_gnn_model = StationFlowGCN(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_nodes=train_loader.dataset[0].x.shape[0],\n",
    "    embeddings=embeddings_n2v,\n",
    "    freeze=True\n",
    ")\n",
    "\n",
    "train_gnn_model(nodes_gnn_model, train_config, train_loader, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = eval_gnn_model(nodes_gnn_model, test_loader,train_config)\n",
    "print(\"\\t\".join([f\"{metric_name}: {metric_value}\" for metric_name, metric_value in test_metrics.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GATConv Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = dict(\n",
    "    epochs = 20,\n",
    "    lr = 0.01,\n",
    "    criterion = dict(\n",
    "        node=torch.nn.L1Loss(),\n",
    "        edge=torch.nn.L1Loss(),\n",
    "        # regul=regul_edge_node_flow(),\n",
    "    ),\n",
    "    metrics = dict(\n",
    "        MAE=torch.nn.L1Loss(),\n",
    "        MAPE=MAPE_loss()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using node embedding as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialized + updated during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Unweighted edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = dict(\n",
    "    node_target_name = 'traffic',\n",
    "    edge_target_name = 'traffic',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "total_train_degraded_graphs = list(chain.from_iterable([train_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_dev_degraded_graphs = list(chain.from_iterable([dev_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_test_degraded_graphs = list(chain.from_iterable([test_degraded_graphs[i] for i in range(1,11)]))\n",
    "\n",
    "\n",
    "train_loader = get_degraded_network_loader(total_train_degraded_graphs, **loader_config)\n",
    "dev_loader = get_degraded_network_loader(total_dev_degraded_graphs, **loader_config)\n",
    "test_loader = get_degraded_network_loader(total_test_degraded_graphs, **loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "output_dim = 1\n",
    "\n",
    "nodes_gnn_model = StationFlowGAT(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_nodes=train_loader.dataset[0].x.shape[0],\n",
    "    embeddings='initialized',\n",
    "    num_heads=4\n",
    ")\n",
    "\n",
    "train_gnn_model(nodes_gnn_model, train_config, train_loader, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = eval_gnn_model(nodes_gnn_model, test_loader,train_config)\n",
    "print(\"\\t\".join([f\"{metric_name}: {metric_value}\" for metric_name, metric_value in test_metrics.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Weighted edges (based on node position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = dict(\n",
    "    node_target_name = 'traffic',\n",
    "    edge_target_name = 'traffic',\n",
    "    edge_feature_names = ['weight'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "total_train_degraded_graphs = list(chain.from_iterable([train_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_dev_degraded_graphs = list(chain.from_iterable([dev_degraded_graphs[i] for i in range(1,11)]))\n",
    "total_test_degraded_graphs = list(chain.from_iterable([test_degraded_graphs[i] for i in range(1,11)]))\n",
    "\n",
    "\n",
    "train_loader = get_degraded_network_loader(total_train_degraded_graphs, **loader_config)\n",
    "dev_loader = get_degraded_network_loader(total_dev_degraded_graphs, **loader_config)\n",
    "test_loader = get_degraded_network_loader(total_test_degraded_graphs, **loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "output_dim = 1\n",
    "\n",
    "nodes_gnn_model = StationFlowGAT(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_nodes=train_loader.dataset[0].x.shape[0],\n",
    "    embeddings='initialized',\n",
    "    edge_dim=1\n",
    ")\n",
    "\n",
    "train_gnn_model(nodes_gnn_model, train_config, train_loader, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = eval_gnn_model(nodes_gnn_model, test_loader,train_config)\n",
    "print(\"\\t\".join([f\"{metric_name}: {metric_value}\" for metric_name, metric_value in test_metrics.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.explain.metric import fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs = 5,\n",
    "    lr = 0.001,\n",
    "    criterion = torch.nn.L1Loss(),\n",
    "    metrics = dict(\n",
    "        MAE=torch.nn.L1Loss(),\n",
    "        MAPE=MAPE_loss()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_target_name = 'traffic'\n",
    "node_feature_names=['x', 'y']\n",
    "\n",
    "train_loader = get_degraded_network_loader(train_degraded_graphs, node_target_name=node_target_name, node_feature_names=node_feature_names, shuffle=True)\n",
    "dev_loader = get_degraded_network_loader(dev_degraded_graphs, node_target_name=node_target_name, node_feature_names=node_feature_names, shuffle=True)\n",
    "test_loader = get_degraded_network_loader(test_degraded_graphs, node_target_name=node_target_name, node_feature_names=node_feature_names, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_loader.dataset[0].x.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "nodes_gnn_model = StationFlowGCN(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_nodes=train_loader.dataset[0].x.shape[0],\n",
    ")\n",
    "\n",
    "train_gnn_model(nodes_gnn_model, config, train_loader, dev_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=nodes_gnn_model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='node',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")\n",
    "\n",
    "data = test_loader.dataset[0]\n",
    "idx_chtl_4 = test_network.network_stations['Châtelet']['4']\n",
    "\n",
    "explanation = explainer(data.x, data.edge_index, index=idx_chtl_4)\n",
    "print(explanation.edge_mask)\n",
    "print(explanation.node_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = nx.get_node_attributes(test_network.network_graph, 'title')\n",
    "explanation.visualize_graph(node_labels=node_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
