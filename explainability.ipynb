{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability of GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "import os\n",
    "import networkx as nx\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from gnn_model import StationFlowGCN\n",
    "from train_gnn import(\n",
    "    train_node_gnn_model,\n",
    "    MAPE_loss\n",
    ")\n",
    "from utils.station_network import StationNetworkSimul\n",
    "from utils.data import get_degraded_network_loader, create_degraded_networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data & generating network dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv('plan du métro.csv')\n",
    "df_stations = df_stations[~df_stations['vers Ligne'].isin(['\\xa01', '\\xa07', '\\xa02', '\\xa08', '\\xa06'])]\n",
    "\n",
    "df_pos = pd.read_csv(\"position gps des stations de métro.csv\")\n",
    "\n",
    "#Removing Malsesherbes RER Station\n",
    "df_pos = df_pos.drop([151])\n",
    "\n",
    "df_flow = pd.read_csv('passagers.csv')\n",
    "df_flow['nombre'] = df_flow['nombre'].astype(float)\n",
    "path_flows = df_flow[['de', 'vers', 'nombre']].to_dict('records')\n",
    "\n",
    "network_simul = StationNetworkSimul(df_stations=df_stations, df_pos=df_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_simul.set_edges_weights()\n",
    "network_simul.set_nodes_traffic(path_flows=path_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"graph_dataset/\"\n",
    "\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "num_delete = 1\n",
    "num_degraded=50\n",
    "\n",
    "create_degraded_networks(network_simul, df_flow, num_delete=num_delete, num_degraded=num_degraded, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_degraded_graphs = []\n",
    "dev_degraded_graphs = []\n",
    "test_degraded_graphs = []\n",
    "\n",
    "train_test_ratio = 0.9\n",
    "dev_train_ratio = 0.1\n",
    "\n",
    "\n",
    "folder_path = os.path.join(data_dir, f'delete_{num_delete}')\n",
    "all_files = [file_path for file_path in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file_path))]\n",
    "degraded_graphs = []\n",
    "for file_path in all_files:\n",
    "    with open(os.path.join(folder_path, file_path), 'rb') as f:\n",
    "        new_net = pickle.load(f)\n",
    "    degraded_graphs.append(new_net)\n",
    "\n",
    "train_split_idx = int(train_test_ratio*len(all_files))\n",
    "dev_split_idx = int(dev_train_ratio*train_split_idx)\n",
    "\n",
    "dev_degraded_graphs.extend(degraded_graphs[:dev_split_idx])\n",
    "train_degraded_graphs.extend(degraded_graphs[dev_split_idx:train_split_idx])\n",
    "test_degraded_graphs.extend(degraded_graphs[train_split_idx:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs = 5,\n",
    "    lr = 0.001,\n",
    "    criterion = torch.nn.L1Loss(),\n",
    "    metrics = dict(\n",
    "        MAE=torch.nn.L1Loss(),\n",
    "        MAPE=MAPE_loss()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_target_name = 'traffic'\n",
    "node_feature_names=['x', 'y']\n",
    "\n",
    "train_loader = get_degraded_network_loader(train_degraded_graphs, node_target_name=node_target_name, node_feature_names=node_feature_names, shuffle=True)\n",
    "dev_loader = get_degraded_network_loader(dev_degraded_graphs, node_target_name=node_target_name, node_feature_names=node_feature_names, shuffle=True)\n",
    "test_loader = get_degraded_network_loader(test_degraded_graphs, node_target_name=node_target_name, node_feature_names=node_feature_names, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_loader.dataset[0].x.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "nodes_gnn_model = StationFlowGCN(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_nodes=train_loader.dataset[0].x.shape[0],\n",
    ")\n",
    "\n",
    "train_node_gnn_model(nodes_gnn_model, config, train_loader, dev_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=nodes_gnn_model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='node',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")\n",
    "\n",
    "data = test_loader.dataset[0]\n",
    "idx_chtl_4 = network_simul.network_stations['Châtelet']['4']\n",
    "\n",
    "explanation = explainer(data.x, data.edge_index, index=idx_chtl_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = nx.get_node_attributes(network_simul.network_graph, 'title')\n",
    "explanation.visualize_graph(node_labels=node_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
